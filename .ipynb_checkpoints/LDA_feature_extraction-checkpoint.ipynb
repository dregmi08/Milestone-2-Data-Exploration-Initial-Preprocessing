{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73zH9-795GGp",
    "outputId": "d22982bf-23d2-44e6-c1a0-0180a0364d9c"
   },
   "source": [
    "# Project Overview\n",
    "## Dataset explanation: Spotify User Review Dataset\n",
    "Our initial dataset, after dropping irrelevant columns, will have 3 columns (before creating our own features). These features are: Review, Total_thumbsup, and Rating. The Review column contains a textual review that a user left, the Total_thumbsup column contains the number of \n",
    "thumbs up a review receives, and the rating contains the corresponding star rating that the user left on the app.\n",
    "\n",
    "## Project Overview/Breakdown\n",
    "Essentially, our project first classifies the reviews in the dataset into three categories: negative, positive, and neutral, and then takes all reviews classified as negative, and ranks the features from most important (the issue that users are complaining the most about) to least\n",
    "important. Our project has two models: one for classifying the sentiment, and one for ranking.\n",
    "\n",
    "## Things to note in regards to building our model/testing\n",
    "\n",
    "### Part 1\n",
    "The first model is pretty straightforward, we basically classified the reviews based on sentiment into good, positive, and neutral, and we verified our results by checking if a review that was classified as positive had 4-5 stars, checking if a review classified as neutral had 3 stars, and seeing if a review classified as negative had a 1-2 star rating. \n",
    "\n",
    "### Part 2\n",
    "Our second part (the ranking step) falls more into the category of unsupervised learning. What we decided to do was use Latent Dirichlet Allocation (LDA), which is a technique used for topic modeling to extract different topics amongst the reviews. Each topic has a corresponding sentiment score, and we got the top 10 positive topics (topics with the highest sentiment scores), and top 10 negative topics (topics with the lowest sentiment scores), and assigned descriptive labels to the negative topics (because we are concerned with ranking issues that users complain about). The topic with the lowest sentiment score was assigned the highest ranking, and the topic with the highest sentiment score among all negative topics was assigned the lowest ranking. The tricky part of this milestone was within testing\n",
    "the second part, since we had to go through our reviews and assign the negative reviews with the labels our own labels (we didn't really have a ground truth in the dataset that we could go off of, so we had to create it ourselves), so we used Hugging Face's zero-shot classifier to create a ground truth for us (we passed it the labels for the negative topics) and compared the rankings from this to the rankings our lda model came up with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73zH9-795GGp",
    "outputId": "d22982bf-23d2-44e6-c1a0-0180a0364d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.46.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.0\n",
      "fatal: destination path 'Milestone-2-Data-Exploration-Initial-Preprocessing' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Import/pip install all of the necessary libraries\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn \n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentence-transformers\n",
    "\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/dregmi08/Milestone-2-Data-Exploration-Initial-Preprocessing.git\n",
    "\n",
    "# Include all imports \n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "EGY2BKK05N-h",
    "outputId": "a9d5211a-4065-4f0b-ef2f-25ae20b51e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review  Rating  \\\n",
      "0      Great music service, the audio is high quality...       5   \n",
      "1      Please ignore previous negative rating. This a...       5   \n",
      "2      This pop-up \"Get the best Spotify experience o...       4   \n",
      "3        Really buggy and terrible to use as of recently       1   \n",
      "4      Dear Spotify why do I get songs that I didn't ...       1   \n",
      "...                                                  ...     ...   \n",
      "61589  Even though it was communicated that lyrics fe...       1   \n",
      "61590  Use to be sooo good back when I had it, and wh...       1   \n",
      "61591  This app would be good if not for it taking ov...       2   \n",
      "61592  The app is good hard to navigate and won't jus...       2   \n",
      "61593  Its good but sometimes it doesnt load the musi...       4   \n",
      "\n",
      "       Total_thumbsup  \n",
      "0                   2  \n",
      "1                   1  \n",
      "2                   0  \n",
      "3                   1  \n",
      "4                   1  \n",
      "...               ...  \n",
      "61589               6  \n",
      "61590               0  \n",
      "61591              10  \n",
      "61592               1  \n",
      "61593               0  \n",
      "\n",
      "[61594 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas data frame from our csv file\n",
    "data = pd.read_csv('Milestone-2-Data-Exploration-Initial-Preprocessing/reviews.csv')\n",
    "\n",
    "# Dropping the unnecessary columns: timesubmitted is the time which the user submitted the review, which is irrelevant to our project\n",
    "# The Reply column is over 99.6% null, so we will be dropping that as well since there is not much information that we can extract to \n",
    "#train our model\n",
    "data = data.drop(columns=['Time_submitted', 'Reply'])\n",
    "\n",
    "# Display the data frame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Dv4WsY765dFW"
   },
   "outputs": [],
   "source": [
    "# This cell contains basic preprocessing for our reviews, we want to remove stop words (words that contain/contribute no valuable information\n",
    "# (like and, I, she, her), we do this to ensure our review text only has words that provide useful information), convert all text to\n",
    "# lowercase, and removing numbers/punctuation\n",
    "def preprocess_reviews(text_series):\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text_series = text_series.str.lower() \n",
    "\n",
    "    # Remove punctuation\n",
    "    text_series = text_series.str.replace(r'[^\\w\\s]', '')  \n",
    "\n",
    "    # Remove numbers\n",
    "    text_series = text_series.str.replace(r'\\d+', '')\n",
    "\n",
    "    #Return filtered reviews\n",
    "    return text_series\n",
    "\n",
    "# Create a new feature in the dataset that now contains the preprocessed version of all reviews\n",
    "data['Review_clean'] = preprocess_reviews(data['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I99Kus2154he"
   },
   "outputs": [],
   "source": [
    "# Creates a tool to turn text into a matrix of word/phrase counts, focusing on the 1000 most common ones, ignoring common stop words.\n",
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "# Convert the cleaned reviews into a matrix of numbers, where each row is a review and each column is a word or phrase\n",
    "X = vectorizer.fit_transform(data['Review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OB9SgWgO59n9"
   },
   "outputs": [],
   "source": [
    "# Creates an LDA model to find 20 topics in the data, where each topic is a group of related words.\n",
    "lda = LatentDirichletAllocation(n_components=20, random_state=0)\n",
    "\n",
    "# Trains the LDA model on the numerical feature matrix (X) to learn the topics.\n",
    "lda.fit(X)\n",
    "\n",
    "# Transforms the data into a topic representation, showing the topic distribution for each document.\n",
    "topics = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y4TnXb4P6FWC"
   },
   "outputs": [],
   "source": [
    "def get_sentiment_score(rating):\n",
    "    if rating >= 4:\n",
    "        return 1  # Positive\n",
    "    elif rating <= 2:\n",
    "        return -1  # Negative\n",
    "    else:\n",
    "        return 0  # Neutral\n",
    "\n",
    "data['sentiment_score'] = data['Rating'].apply(get_sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPMi4d6k6SFB",
    "outputId": "a1f1fb38-b7cd-4ee4-e240-f9f457c99e51",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words per topic:\n",
      "      Topic 1      Topic 2  Topic 3  Topic 4       Topic 5       Topic 6  \\\n",
      "0    stopping      app use   logged   update       pandora         music   \n",
      "1        time  use spotify  spotify   button   spotify app         worth   \n",
      "2    multiple        apple      try     play          just         money   \n",
      "3  constantly    recommend    tried    pause  love spotify        paying   \n",
      "4     crashes      use app      won    close          adds  subscription   \n",
      "5       times        music      let   screen           app       version   \n",
      "6    crashing          app      log     open        better       spotify   \n",
      "7     podcast     easy use      app  playing          love           pay   \n",
      "8       keeps         easy  premium     song          like          free   \n",
      "9         app          use  account      app       spotify       premium   \n",
      "\n",
      "     Topic 7    Topic 8          Topic 9       Topic 10    Topic 11  \\\n",
      "0  listening     random            great  using spotify        mode   \n",
      "1   annoying  song want  music streaming           used     shuffle   \n",
      "2       free    shuffle        selection         really      listen   \n",
      "3       song       just     love spotify       good app  play songs   \n",
      "4    minutes      plays          spotify             ve        able   \n",
      "5        app  play song        streaming          years  downloaded   \n",
      "6      songs       want              app        spotify     offline   \n",
      "7         30   playlist            music          using   playlists   \n",
      "8         ad       play         love app            app        play   \n",
      "9        ads       song             love           good       songs   \n",
      "\n",
      "     Topic 12  Topic 13       Topic 14      Topic 15    Topic 16  \\\n",
      "0    download     pause  sound quality  listen music    best app   \n",
      "1  new update       bar        podcast   want listen   app music   \n",
      "2       songs      play        content          know        nice   \n",
      "3      really  randomly       features          like     amazing   \n",
      "4   great app    update           just         music      listen   \n",
      "5         new     stops            app          just  best music   \n",
      "6      lyrics      stop          audio         songs   music app   \n",
      "7      update     music          sound        listen        best   \n",
      "8         app       app       podcasts           don       music   \n",
      "9       great   playing        quality          want         app   \n",
      "\n",
      "         Topic 17             Topic 18    Topic 19         Topic 20  \n",
      "0            just  internet connection  doesn work              app  \n",
      "1     liked songs                 wifi     spotify  listening music  \n",
      "2  songs playlist                  fix   bluetooth         podcasts  \n",
      "3            song              spotify        time            enjoy  \n",
      "4             app                issue         car             like  \n",
      "5           liked                 data     android             good  \n",
      "6             add           connection       phone          spotify  \n",
      "7            like              working        work        listening  \n",
      "8        playlist             internet         app            great  \n",
      "9           songs                  app       doesn            music  \n"
     ]
    }
   ],
   "source": [
    "# Number of top terms to display per topic (10 most frequent words for each topic)\n",
    "n_top_terms = 10\n",
    "\n",
    "# Get the list of all words (terms) from the vectorizer's feature names\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary to store the top terms for each topic\n",
    "topic_features = {}\n",
    "\n",
    "# Loop through each topic and find the top terms (words) for that topic\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    # Sort the terms in the topic by their importance and pick the top 10\n",
    "    top_terms = [terms[i] for i in topic.argsort()[-n_top_terms:]]\n",
    "    topic_features[f\"Topic {topic_idx + 1}\"] = top_terms\n",
    "\n",
    "# Convert the topic features dictionary into a DataFrame for easier viewing\n",
    "topic_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in topic_features.items()]))\n",
    "\n",
    "# Display the top words for each topic\n",
    "print(\"Top words per topic:\")\n",
    "print(topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUYWWLw_6TY5",
    "outputId": "7b0e90d0-6003-416f-da31-ea62de92f5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Topics Users Like:\n",
      "       topic        score  normalized_score\n",
      "15  Topic 16  3020.806763          0.745585\n",
      "8    Topic 9  2340.063542          0.737194\n",
      "19  Topic 20  3242.680488          0.705284\n",
      "1    Topic 2  1146.795218          0.545380\n",
      "9   Topic 10  1307.820248          0.429498\n",
      "4    Topic 5   774.158178          0.284225\n",
      "11  Topic 12   758.022529          0.245205\n",
      "16  Topic 17   615.677959          0.156919\n",
      "13  Topic 14    55.142448          0.022183\n",
      "14  Topic 15  -169.354441         -0.055577\n",
      "\n",
      "Top Topics Users Dislike:\n",
      "       topic        score  normalized_score\n",
      "5    Topic 6  -227.016084         -0.066016\n",
      "6    Topic 7  -274.489721         -0.083906\n",
      "10  Topic 11  -236.561898         -0.092828\n",
      "17  Topic 18  -703.882683         -0.279378\n",
      "7    Topic 8 -1062.574623         -0.290089\n",
      "18  Topic 19  -833.140003         -0.303686\n",
      "0    Topic 1  -830.862538         -0.341637\n",
      "3    Topic 4  -891.818240         -0.347985\n",
      "2    Topic 3 -1067.583096         -0.409248\n",
      "12  Topic 13 -1797.884046         -0.504576\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sentiment scores for each topic by multiplying the topic distribution matrix with sentiment scores of each review\n",
    "topic_sentiment_scores = np.dot(topics.T, data['sentiment_score'])\n",
    "\n",
    "# Get the frequency of each topic across all reviews\n",
    "topic_frequencies = topics.sum(axis=0)\n",
    "\n",
    "# Normalize the sentiment scores by dividing by the frequency of each topic to account for topic popularity\n",
    "normalized_topic_scores = topic_sentiment_scores / topic_frequencies\n",
    "\n",
    "# Create a DataFrame to store topic scores and normalized scores for easy comparison\n",
    "topic_score_df = pd.DataFrame({\n",
    "    'topic': [f'Topic {i+1}' for i in range(len(topic_sentiment_scores))],\n",
    "    'score': topic_sentiment_scores,\n",
    "    'normalized_score': normalized_topic_scores\n",
    "})\n",
    "\n",
    "# Sort topics by their normalized sentiment score (from most liked to most disliked)\n",
    "topic_score_df = topic_score_df.sort_values(by='normalized_score', ascending=False)\n",
    "\n",
    "# Display the top 10 topics that users like (highest normalized scores)\n",
    "print(\"Top Topics Users Like:\")\n",
    "print(topic_score_df.head(10))\n",
    "\n",
    "# Display the bottom 10 topics that users dislike (lowest normalized scores)\n",
    "print(\"\\nTop Topics Users Dislike:\")\n",
    "print(topic_score_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bbTHQMEW69fy"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "np.int64(25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 25",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_classified_reviews\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Classify the reviews in batches\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m classified_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_reviews_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative_reviews_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Create DataFrame with results\u001b[39;00m\n\u001b[1;32m     68\u001b[0m classified_reviews_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(classified_reviews)\n",
      "Cell \u001b[0;32mIn[15], line 44\u001b[0m, in \u001b[0;36mclassify_reviews_batch\u001b[0;34m(reviews, candidate_labels, model, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m batch_reviews \u001b[38;5;241m=\u001b[39m reviews[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Generate embeddings for the batch of reviews\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m review_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_reviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarities in batch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mpytorch_cos_sim(review_embeddings, label_embeddings)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:587\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    586\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[0;32m--> 587\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [\u001b[43msentences\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    590\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index : start_index \u001b[38;5;241m+\u001b[39m batch_size]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: np.int64(25)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Manually assign labels for the topics (negative reviews)\n",
    "topic_labels = {\n",
    "    'Topic 1': \"Connectivity and Streaming Failures\",\n",
    "    'Topic 3': 'App Instability',\n",
    "    'Topic 4': 'Subscription and Payment Problems',\n",
    "    'Topic 6': 'Audio and Sound Quality Problems',\n",
    "    'Topic 7': 'Ads and Interruptions',\n",
    "    'Topic 8': 'Playback and Control Issues',\n",
    "    'Topic 11': \"Music Discovery and Recommendation Failures\",\n",
    "    'Topic 13': 'Random Music Pausing',\n",
    "    'Topic 18': 'App Usability Frustrations',\n",
    "    'Topic 19': \"Device and Platform Compatibility Issues\"\n",
    "}\n",
    "\n",
    "# Define candidate labels\n",
    "candidate_labels = [\n",
    "    \"Connectivity and Streaming Failures\", 'App Instability', 'Subscription and Payment Problems',\n",
    "    'Audio and Sound Quality Problems', 'Ads and Interruptions', 'Playback and Control Issues',\n",
    "    \"Music Discovery and Recommendation Failures\", 'App Usability Frustrations', \"Device and Platform Compatibility Issues\"\n",
    "]\n",
    "\n",
    "\n",
    "# Load the Sentence-Transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Select a smaller subset for faster testing (negative reviews with low ratings, e.g., 1 or 2)\n",
    "negative_reviews_subset = data[data['Rating'].isin([1, 2])]['Review_clean'].sample(n=1000, random_state=42).tolist()\n",
    "\n",
    "# Function to classify each review using Sentence-Transformer embeddings (Batch Processing)\n",
    "def classify_reviews_batch(reviews, candidate_labels, model, batch_size=32):\n",
    "    # Generate embeddings for all candidate labels (just once, not per review)\n",
    "    label_embeddings = model.encode(candidate_labels, convert_to_tensor=True)\n",
    "    \n",
    "    # Process reviews in batches\n",
    "    all_classified_reviews = []\n",
    "    \n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        batch_reviews = reviews[i:i+batch_size]\n",
    "        \n",
    "        # Generate embeddings for the batch of reviews\n",
    "        review_embeddings = model.encode(batch_reviews, convert_to_tensor=True)\n",
    "        \n",
    "        # Calculate cosine similarities in batch\n",
    "        cosine_similarities = util.pytorch_cos_sim(review_embeddings, label_embeddings)\n",
    "        \n",
    "        # Process each review in the batch\n",
    "        for j, review in enumerate(batch_reviews):\n",
    "            similarities = cosine_similarities[j]\n",
    "            max_sim_idx = similarities.argmax()\n",
    "            predicted_label = candidate_labels[max_sim_idx]\n",
    "            score = similarities[max_sim_idx].item()  # Extract the scalar value from tensor\n",
    "            \n",
    "            all_classified_reviews.append({\n",
    "                'Review': review,\n",
    "                'Predicted Label': predicted_label,\n",
    "                'Score': score\n",
    "            })\n",
    "    \n",
    "    return all_classified_reviews\n",
    "\n",
    "# Classify the reviews in batches\n",
    "classified_reviews = classify_reviews_batch(negative_reviews_subset, candidate_labels, model)\n",
    "\n",
    "# Create DataFrame with results\n",
    "classified_reviews_df = pd.DataFrame(classified_reviews)\n",
    "\n",
    "# Display the results\n",
    "print(classified_reviews_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
